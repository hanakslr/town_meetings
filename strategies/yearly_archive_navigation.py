# This strategy was initially autogenerated by Claude.
# Additional transformation was applied afterwards to structure it as a useful class.

from strategies import FetchingStrategy
import re
from bs4 import BeautifulSoup
import requests
from datetime import datetime
import calendar


class YearlyArchiveNavigation(FetchingStrategy):
    """This strategy navigates to the committee's main page and finds all links to yearly archives. It then visits each yearly archive page and extracts meeting dates and URLs from the links on those pages. The strategy handles various date formats and skips meetings that are marked as cancelled or postponed."""

    name = "yearly_archive_navigation"

    def fetch(self, *, base_url, committee_identifier, committee_page_url):
        """
        Args:
            base_url: The base URL of the town website
            committee_identifier: Unique identifier used in URLs for the committee
            committee_page_url: URL to the main committee page with links to yearly archives

        Returns:
            List of {date, agenda}
        """
        # Get the committee page with links to yearly archives
        response = requests.get(committee_page_url)
        soup = BeautifulSoup(response.text, "html.parser")

        # Find all year archive links for this committee
        year_links = []
        for link in soup.find_all("a"):
            link_text = link.get_text(strip=True)
            # Look for links containing the committee identifier and a year
            if committee_identifier in link_text and re.search(r"20\d{2}", link_text):
                # Extract the year from the link text
                year_match = re.search(r"(20\d{2})", link_text)
                if year_match and "href" in link.attrs:
                    year = year_match.group(1)
                    # Convert relative URLs to absolute
                    if link["href"].startswith("http"):
                        year_url = link["href"]
                    else:
                        year_url = f"{base_url}/{link['href']}"

                    year_links.append({"year": year, "url": year_url})

        # Collect all meeting agendas from all years
        meeting_agendas = []

        for year_link in year_links:
            year = year_link["year"]
            year_url = year_link["url"]

            response = requests.get(year_url)
            soup = BeautifulSoup(response.text, "html.parser")

            # Find all meeting links on the yearly archive page
            for link in soup.find_all("a"):
                link_text = link.get_text(strip=True)

                # Skip links that are obviously not meeting links
                if "href" not in link.attrs or not link_text or len(link_text) < 5:
                    continue

                # Skip links with cancelled meetings
                if (
                    "cancel" in link_text.lower()
                    or "no meeting" in link_text.lower()
                    or "postponed" in link_text.lower()
                ):
                    continue

                # Try to extract a date from the link text
                # Handle various date formats including "Month Day, Year" and "Month Day Year"
                date_match = re.search(
                    r"([A-Z][a-z]+)\s+(\d+)(?:,?\s+|\s*[-,]?\s*)(20\d{2})", link_text
                )

                if date_match:
                    month_name = date_match.group(1)
                    day = date_match.group(2)
                    year = date_match.group(3)
                else:
                    # Try to match just month and day for rescheduled meetings
                    date_match = re.search(r"([A-Z][a-z]+)\s+(\d+)", link_text)
                    if date_match:
                        month_name = date_match.group(1)
                        day = date_match.group(2)
                        # Use the year from the year_link
                        year = year_link["year"]
                    else:
                        continue  # No date found, skip this link

                # Convert month name to number
                try:
                    month_num = str(list(calendar.month_name).index(month_name)).zfill(
                        2
                    )
                except ValueError:
                    # Try to match abbreviated month names
                    month_abbr = month_name[:3].title()
                    try:
                        month_num = str(
                            list(calendar.month_abbr).index(month_abbr)
                        ).zfill(2)
                    except ValueError:
                        continue

                # Format the date as YYYY-MM-DD
                formatted_date = f"{year}-{month_num}-{day.zfill(2)}"

                # Create the full URL for the meeting page
                if link["href"].startswith("http"):
                    meeting_url = link["href"]
                else:
                    meeting_url = f"{base_url}/{link['href']}"

                # Add to our list of meetings
                meeting_agendas.append({"date": formatted_date, "agenda": meeting_url})

        return meeting_agendas
